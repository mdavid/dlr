/* ****************************************************************************
 *
 * Copyright (c) Microsoft Corporation. 
 *
 * This source code is subject to terms and conditions of the Microsoft Public License. A 
 * copy of the license can be found in the License.html file at the root of this distribution. If 
 * you cannot locate the  Microsoft Public License, please send an email to 
 * ironruby@microsoft.com. By using this source code in any fashion, you are agreeing to be bound 
 * by the terms of the Microsoft Public License.
 *
 * You must not remove this notice, or any other, from this software.
 *
 *
 * ***************************************************************************/

using System; using Microsoft;
using System.Collections.Generic;
using System.Diagnostics;
using Microsoft.Scripting;
using System.Text;
using Microsoft.Scripting.Runtime;
using Microsoft.Scripting.Utils;
using IronRuby.Compiler.Ast;
using IronRuby.Runtime;
using IronRuby.Builtins;

namespace IronRuby.Compiler {

    // The non-autogenerated part of the Parser class.
    [System.Diagnostics.CodeAnalysis.SuppressMessage("Microsoft.Maintainability", "CA1506:AvoidExcessiveClassCoupling")]
    public partial class Parser {
        internal sealed class InternalSyntaxError : Exception {
        }

        private int _inSingletonMethodDefinition = 0;
        private int _inInstanceMethodDefinition = 0;

        private SourceUnitTree _ast;
        private List<Initializer> _initializers; // lazy

        private Stack<LexicalScope>/*!*/ _lexicalScopes = new Stack<LexicalScope>();
        private SourceUnit _sourceUnit;
        private readonly Tokenizer/*!*/ _tokenizer;
        private Action<Tokens, SourceSpan> _tokenSink;
        private int _generatedNameId;

        // current encoding (used for __ENCODING__ pseudo-constant, literal string, symbol, regex encodings):
        private Encoding/*!*/ _encoding;

        internal Encoding/*!*/ Encoding {
            get { return _encoding; }
        }
        
        private bool InMethod {
            get { return _inSingletonMethodDefinition > 0 || _inInstanceMethodDefinition > 0; }
        }

        public Tokenizer/*!*/ Tokenizer {
            get { return _tokenizer; }
        }

        public ErrorSink/*!*/ ErrorSink {
            get { return _tokenizer.ErrorSink; }
        }

        public Action<Tokens, SourceSpan> TokenSink {
            get { return _tokenSink; }
            set { _tokenSink = value; }
        }

        protected override SourceSpan TokenSpan {
            get {
                return _tokenizer.TokenSpan;
            }
        }

        protected override TokenValue TokenValue {
            get {
                return _tokenizer.TokenValue;
            }
        }

        protected override SourceSpan DefaultTokenSpan {
            get { return SourceSpan.None; }
        }

        protected override int GetNextToken() {
            Tokens token = _tokenizer.GetNextToken();
            if (_tokenSink != null) {
                _tokenSink(token, _tokenizer.TokenSpan);
            }
            return (int)token;
        }

        protected override void ReportSyntaxError(string message) {
            ErrorSink.Add(_sourceUnit, message, TokenSpan, -1, Severity.FatalError);
            throw new InternalSyntaxError();
        }

        internal void ReportSyntaxError(ErrorInfo error) {
            ErrorSink.Add(_sourceUnit, error.GetMessage(), TokenSpan, error.Code, Severity.FatalError);
            throw new InternalSyntaxError();
        }

        private string/*!*/ GenerateErrorLocalName() {
            return "error#" + _generatedNameId++;
        }

        private string/*!*/ GenerateErrorConstantName() {
            return "Error#" + _generatedNameId++;
        }

        public Parser() 
            : this(ErrorSink.Default) {
        }

        // TODO:
        public Parser(ErrorSink/*!*/ errorSink) {
            _tokenizer = new Tokenizer(this);
        }

        public SourceUnitTree Parse(SourceUnit/*!*/ sourceUnit, RubyCompilerOptions/*!*/ options, ErrorSink/*!*/ errorSink) {
            Assert.NotNull(sourceUnit, options, errorSink);

            ErrorCounter counter = new ErrorCounter(errorSink);
            _tokenizer.ErrorSink = counter;
            _tokenizer.Compatibility = options.Compatibility;

            _lexicalScopes.Clear();

            EnterScope(CreateTopScope(options.LocalNames));

            using (SourceCodeReader reader = sourceUnit.GetReader()) {
                _sourceUnit = sourceUnit;
                _tokenizer.Initialize(null, reader, sourceUnit, options.InitialLocation);

                // default encoding when hosted:
                _encoding = reader.Encoding ?? RubyEncoding.GetDefaultHostEncoding(options.Compatibility);

                try {
                    Parse();
                    LeaveScope();
                } catch (InternalSyntaxError) {
                    _ast = null;
                    _lexicalScopes.Clear();
                } finally {
                    ScriptCodeParseResult props;
                    if (counter.AnyError) {
                        _ast = null;

                        if (_tokenizer.UnterminatedToken) {
                            props = ScriptCodeParseResult.IncompleteToken;
                        } else if (_tokenizer.IsEndOfFile) {
                            props = ScriptCodeParseResult.IncompleteStatement;
                        } else {
                            props = ScriptCodeParseResult.Invalid;
                        }
                        
                    } else {
                        props = ScriptCodeParseResult.Complete;
                    }

                    sourceUnit.CodeProperties = props;
                }

                return _ast;
            }
        }

        // Top level scope is created for top level code. 
        // Variables defined outside of compilation unit (we are compiling eval) are stored in "outer scope", 
        // to which the top level scope is nested in such case.
        private static LexicalScope/*!*/ CreateTopScope(List<string> localVariableNames) {
            LexicalScope outer;
            if (localVariableNames != null) {
                outer = new RuntimeLexicalScope(localVariableNames);
            } else {
                outer = null;
            }

            return new LexicalScope(outer);
        }

        private LocalVariable/*!*/ DefineParameter(string/*!*/ name, SourceSpan location) {
            // we are in a method:
            Debug.Assert(CurrentScope.OuterScope == null);

            LocalVariable variable;
            if (CurrentScope.TryGetValue(name, out variable)) {
                _tokenizer.ReportError(Errors.DuplicateParameterName);
                return variable;
            }

            return CurrentScope.AddVariable(name, location);
        }

        private Initializer/*!*/ AddInitializer(Initializer/*!*/ initializer) {
            if (_initializers == null) {
                _initializers = new List<Initializer>();
            }

            _initializers.Add(initializer);

            return initializer;
        }
        
        protected override SourceSpan MergeLocations(SourceSpan start, SourceSpan end) {
            Debug.Assert(start.IsValid && end.IsValid);

            return new SourceSpan(start.Start, end.End);
        }

        private LexicalScope/*!*/ EnterScope(LexicalScope/*!*/ scope) {
            Assert.NotNull(scope);
            _lexicalScopes.Push(scope);
            return scope;
        }

        private LexicalScope EnterNestedScope() {
            LexicalScope result = new LexicalScope(CurrentScope);
            _lexicalScopes.Push(result);
            return result;
        }

        private LexicalScope EnterTopScope() {
            LexicalScope result = new LexicalScope(null);
            _lexicalScopes.Push(result);
            return result;
        }

        private LexicalScope LeaveScope() {
            return _lexicalScopes.Pop();
        }

        public LexicalScope CurrentScope {
            get {
                Debug.Assert(_lexicalScopes.Count > 0);
                return _lexicalScopes.Peek();
            }
        }

        // __FILE__
        internal Expression/*!*/ GetCurrentFileExpression(SourceSpan location) {
            if (_sourceUnit.Path == null) {
                return new StringLiteral("(eval)", StringLiteralEncoding.Ascii, location);
            } else {
                var encoding = _sourceUnit.Path.IsAscii() ? StringLiteralEncoding.Ascii : StringLiteralEncoding.Default;
                return new StringLiteral(_sourceUnit.Path, encoding, location);
            }
        }

        internal LeftValue/*!*/ CannotAssignError(string/*!*/ constantName, SourceSpan location) {
            Tokenizer.ReportError(Errors.CannotAssignTo, constantName);
            return CurrentScope.ResolveOrAddVariable(GenerateErrorLocalName(), location);
        }

        private void MatchReferenceReadOnlyError(RegexMatchReference/*!*/ matchRef) {
            Tokenizer.ReportError(Errors.MatchGroupReferenceReadOnly, matchRef.VariableName);
        }

        private AliasStatement/*!*/ MakeGlobalAlias(string/*!*/ newVar, string/*!*/ existingVar, SourceSpan location) {
            return new AliasStatement(false, newVar, existingVar, location);
        }

        private Expression/*!*/ MakeGlobalAlias(string/*!*/ newVar, RegexMatchReference/*!*/ existingVar, SourceSpan location) {
            if (existingVar.CanAlias) {
                return new AliasStatement(false, newVar, existingVar.VariableName, location);
            } else {
                _tokenizer.ReportError(Errors.CannotAliasGroupMatchVariable);
                return new ErrorExpression(location);
            }
        }

        private AliasStatement/*!*/ MakeGlobalAlias(RegexMatchReference/*!*/ newVar, string/*!*/ existingVar, SourceSpan location) {
            return new AliasStatement(false, newVar.VariableName, existingVar, location);
        }

        private Expression/*!*/ MakeGlobalAlias(RegexMatchReference/*!*/ newVar, RegexMatchReference/*!*/ existingVar, SourceSpan location) {
            if (existingVar.CanAlias) {
                return new AliasStatement(false, newVar.VariableName, existingVar.VariableName, location);
            } else {
                _tokenizer.ReportError(Errors.CannotAliasGroupMatchVariable);
                return new ErrorExpression(location);
            }
        }

        private List<T>/*!*/ MakeListAddOpt<T>(T item) {
            List<T> result = new List<T>();
            if (item != null) {
                result.Add(item);
            }
            return result;
        }

        // BlockExpression behaves like an expression, so we don't need to create one that comprises of a single expression:
        private Expression/*!*/ MakeBlockExpression(List<Expression>/*!*/ statements, SourceSpan location) {
            if (statements.Count == 0) {
                return BlockExpression.Empty;
            } else if (statements.Count == 1) {
                return statements[0];
            } else {
                return new BlockExpression(statements, location);
            }
        }

        private IfExpression/*!*/ MakeIfExpression(Expression/*!*/ condition, List<Expression>/*!*/ body, List<ElseIfClause>/*!*/ elseIfClauses, SourceSpan location) {
            // last else-if/else clause is the first one in the list:            
            elseIfClauses.Reverse();
            return new IfExpression(condition, body, elseIfClauses, location);
        }

        private ArrayConstructor/*!*/ MakeVerbatimWords(List<Expression>/*!*/ words, SourceSpan wordsLocation, SourceSpan location) {
            Debug.Assert(CollectionUtils.TrueForAll(words, (word) => word is StringLiteral), "all words are string literals");

            return new ArrayConstructor(new Arguments(words, null, null, wordsLocation), location);
        }

        private List<Expression>/*!*/ CheckHashExpressions(List<Expression>/*!*/ expressions, SourceSpan location) {
            Assert.NotNull(expressions);

            if (expressions.Count % 2 != 0) {
                ErrorSink.Add(_sourceUnit, "odd number list for Hash", location, -1, Severity.Error);
                expressions.Add(Literal.Nil(SourceSpan.None));
            }

            return expressions;
        }

        private Arguments/*!*/ RequireNoBlockArg(TokenValue arguments) {
            if (arguments.Block != null) {
                ErrorSink.Add(_sourceUnit, "block argument should not be given", arguments.Block.Location, -1, Severity.Error);
                arguments.Block = null;
            }

            return arguments.Arguments;
        }

        private static MethodCall/*!*/ MakeMethodCall(Expression target, string/*!*/ methodName, TokenValue args, SourceSpan location) {
            return new MethodCall(target, methodName, args.Arguments, args.Block, location);
        }

        private static MethodCall/*!*/ MakeMethodCall(Expression target, string/*!*/ methodName, TokenValue args, Block block, SourceSpan location) {
            Debug.Assert(args.Block == null);
            return new MethodCall(target, methodName, args.Arguments, block, location);
        }

        private static Expression/*!*/ MakeMatch(Expression/*!*/ left, Expression/*!*/ right, SourceSpan location) {
            var regex = left as RegularExpression;
            if (regex != null) {
                return new MatchExpression(regex, right, location);
            } else {
                return new MethodCall(left, Symbols.Match, new Arguments(right), location);
            }
        }

        private static SuperCall/*!*/ MakeSuperCall(TokenValue args, SourceSpan location) {
            return new SuperCall(args.Arguments, args.Block, location);
        }

        
        // foo 
        // foo {}
        private static TokenValue NoArguments(Block block) {
            return new TokenValue(null, block);
        }

        // foo()
        private static TokenValue MakeArguments() {
            return new TokenValue(Arguments.Empty, null);
        }
        
        // foo()
        // foo() {}
        // foo(&p)
        // foo &p
        private static TokenValue MakeArguments(Block block) {
            return new TokenValue(Arguments.Empty, block);
        }

        // foo(expr)
        private static TokenValue MakeArguments(Expression/*!*/ expression) {
            return new TokenValue(new Arguments(expression), null);
        }

        // foo(expr)
        // foo(expr) {}
        // foo(expr, &p)
        private static TokenValue MakeArguments(Expression/*!*/ expression, Block block) {
            return new TokenValue(new Arguments(expression), block);
        }

        // foo(expr1, ..., exprN, k1 => v1, ..., kN => vN, *a)
        // foo(expr1, ..., exprN, k1 => v1, ..., kN => vN, *a) {}
        // foo(expr1, ..., exprN, k1 => v1, ..., kN => vN, *a, &p)
        private static TokenValue MakeArguments(List<Expression/*!*/> arguments, List<Maplet/*!*/> maplets, Expression array, Block block, SourceSpan location) {
            return new TokenValue(
                new Arguments(arguments, maplets, array, location),
                block
            );
        }

        private static Expression/*!*/ MakeLoopStatement(Expression/*!*/ statement, Expression/*!*/ condition, bool isWhileLoop, SourceSpan location) {
            return new WhileLoopExpression(condition, isWhileLoop, statement is Body, CollectionUtils.MakeList(statement), location);
        }

        public static string/*!*/ TerminalToString(int terminal) {
            Debug.Assert(terminal >= 0);
            if (((Tokens)terminal).ToString() != terminal.ToString()) {
                return IronRuby.Runtime.RubyUtils.MangleName(((Tokens)terminal).ToString()).ToUpper();
            } else {
                return CharToString((char)terminal);
            }
        }

        public static StringLiteral/*!*/ MakeStringLiteral(TokenValue token, SourceSpan location) {
            return new StringLiteral(token.String, token.StringLiteralEncoding, location);
        }

        private StringConstructor/*!*/ MakeSymbolConstructor(List<Expression>/*!*/ content, SourceSpan location) {
            if (content.Count == 0) {
                _tokenizer.ReportError(Errors.EmptySymbolLiteral);
            }
            return new StringConstructor(content, StringKind.Immutable, location);
        }

        // TODO: utils

        public static string/*!*/ CharToString(char ch) {
            switch (ch) {
                case '\a': return @"'\a'";
                case '\b': return @"'\b'";
                case '\f': return @"'\f'";
                case '\n': return @"'\n'";
                case '\r': return @"'\r'";
                case '\t': return @"'\t'";
                case '\v': return @"'\v'";
                case '\0': return @"'\0'";
                default: return String.Concat("'", ch.ToString(), "'");
            }
        }

        public static string/*!*/ EscapeString(string str) {
            return (str == null) ? String.Empty :
                new StringBuilder(str).
                Replace(@"\", @"\\").
                Replace(@"""", @"\""").
                Replace("\a", @"\a").
                Replace("\b", @"\b").
                Replace("\f", @"\f").
                Replace("\n", @"\n").
                Replace("\r", @"\r").
                Replace("\t", @"\t").
                Replace("\v", @"\v").
                Replace("\0", @"\0").ToString();
        }
    }
}


